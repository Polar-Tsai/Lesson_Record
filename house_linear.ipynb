{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0506house_linear.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Polar-Tsai/Lesson_Record/blob/main/house_linear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-EU00pfPHuy"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"https://raw.githubusercontent.com/Elwing-Chou/ml0223/main/house/train.csv\", encoding=\"utf-8\")\n",
        "test_df = pd.read_csv(\"https://raw.githubusercontent.com/Elwing-Chou/ml0223/main/house/test.csv\", encoding=\"utf-8\")\n",
        "train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbnyamOWPfrA"
      },
      "source": [
        "# 合併train、test\n",
        "\n",
        "datas = pd.concat([train_df, test_df], axis=0)\n",
        "datas = datas.drop([\"SalePrice\"], axis=1).reset_index(drop=True)\n",
        "datas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4-38uNXP__u"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.stats import skew\n",
        "from scipy.stats import boxcox_normmax\n",
        "from scipy.special import boxcox1p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIM4-6k7QtyH"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "y = train_df[\"SalePrice\"]\n",
        "print(\"skew:\", skew(y))\n",
        "print(\"lambda:\", boxcox_normmax(1 + y))\n",
        "sns.distplot(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap9V9rIORhNX"
      },
      "source": [
        "# 調整後變常態分佈 with log1p\n",
        "y = train_df[\"SalePrice\"]\n",
        "y_train_log1p = np.log1p(y)\n",
        "print(\"skew:\", skew(y_train_log1p))\n",
        "sns.distplot(y_train_log1p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6soJm0Cw61g"
      },
      "source": [
        "# 調整後變常態分佈 with boxcox1p\n",
        "y = train_df[\"SalePrice\"]\n",
        "lamda = boxcox_normmax(y)\n",
        "y_train_boxcox1p = boxcox1p(y, lamda)\n",
        "print(\"skew:\", skew(y_train_log1p))\n",
        "sns.distplot(y_train_log1p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xvjccbKStIg"
      },
      "source": [
        "# 檢查缺失值\n",
        "s = datas.isna().sum()\n",
        "s[s > 0].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y4GUN7TZA2R"
      },
      "source": [
        "# 去除少一半資料的欄位\n",
        "datas_drop = datas.drop([\"Id\", \"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrDkk7d1avQu"
      },
      "source": [
        "idx = datas_drop.dtypes != \"object\"\n",
        "number_idx = datas_drop.dtypes[idx].index.drop([\"MSSubClass\"])\n",
        "number_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLlSgt_0ZKla"
      },
      "source": [
        "import pandas as pd\n",
        "datas_drop = pd.get_dummies(datas_drop)\n",
        "datas_drop = pd.get_dummies(datas_drop, columns=[\"MSSubClass\"])\n",
        "datas_drop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEf-jQ1XZ2Y0"
      },
      "source": [
        "# 調整偏度\n",
        "def getskew(series):\n",
        "    return skew(series.dropna() + 1)\n",
        "skewness = (datas_drop[number_idx].apply(getskew)\n",
        "                  .sort_values(ascending=False))\n",
        "need_saved = skewness[skewness > 1].index\n",
        "print(need_saved)\n",
        "skewness[skewness > 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB1UKtX3c_G4"
      },
      "source": [
        "def save(s):\n",
        "    lamda = boxcox_normmax(s.dropna() + 1)\n",
        "    return boxcox1p(s, lamda)\n",
        "datas_drop[need_saved] = datas_drop[need_saved].apply(save)\n",
        "skewness = (datas_drop[number_idx].apply(getskew)\n",
        "                  .sort_values(ascending=False))\n",
        "skewness"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JPjcnYJe-cK"
      },
      "source": [
        "# 補上缺失值\n",
        "datas_drop = datas_drop.fillna(datas_drop.median())\n",
        "datas_drop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7wW45klaZx1"
      },
      "source": [
        "## Scaling\n",
        "1. MinMax: 最小值=0；最大值=1\n",
        "> 疑慮: 如果離群值和大家距離差太多，大家的值會因為她而導致都擠在一起\n",
        "2. Standard: (x-μ)/σ 使平均=0；標準差=1\n",
        "3. Robost Scaler: (x-Q1)/(Q3-Q1)\n",
        ">* MinMax改良版\n",
        ">* 去除離群值後，計算間距\n",
        "\n",
        "### 哪個好??都試過才知道"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh9BEpQEvgQp"
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()\n",
        "datas_norm = pd.DataFrame(scaler.fit_transform(datas_drop),\n",
        "              columns\n",
        "              =datas_drop.columns)\n",
        "x_train = datas_norm.iloc[:len(train_df)]\n",
        "\n",
        "x_predict = datas_norm.iloc[len(train_df):]\n",
        "# y_train_log1p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBO0l6wrwgZj"
      },
      "source": [
        "# x_train: 1460 * 300\n",
        "# x_predict: 1459 * 300\n",
        "# y_train_log1p: 1460"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjNdpcNMdkXt"
      },
      "source": [
        "#### 分類類別問題，以非線性函數的表現較佳\n",
        "#### 迴歸類別問題，則以 **線性函數**較好\n",
        "原因:\n",
        "1. 過擬和(些微震盪也放入的話，萬一那些資料是壞資料，反而會導致資料表現差)\n",
        "2. 隨機森林沒有更細微劃分(分支後的結果並沒有做到更好的分類)\n",
        "\n",
        "Skewness偏度:\n",
        "> <0: 左偏；=0: 常態；>0: 右偏\n",
        "\n",
        "---\n",
        "\n",
        "### 線性迴歸本身是不需要做scaling\n",
        "y = a1x1 + a2x3 + a3x3 + b\n",
        "### 但在使用梯度下降下，依然需要做scaling。與此同時，要加上懲罰項\n",
        "Loss(MSE) = (Σ(pre-正確)^2)/n\n",
        "\n",
        "懲罰項\n",
        "1. Lasso Regression(L1正則化)\n",
        ">* 只考慮真正影響非常大的欄位，其他慢慢刪減至無\n",
        ">* **有特徵挑選的效果**\n",
        ">* 好用在特徵過多的資料\n",
        ">>* α(|a1| + |a2| + |a3|)\n",
        ">>* 如果a1下降1，Loss上升5\n",
        ">>* 如果a2下降5，Loss上升1-> Loss變動幅度小，a2設為=0\n",
        "2. Ridge Regression(L2正則化: 嶺迴歸)\n",
        ">* 減少依賴過大係數\n",
        ">* **使係數平衡**\n",
        ">>* α(a1^2 + a2^2 + a3^2)\n",
        "\n",
        "3. ElasticNet Regression\n",
        ">* 結合Lasso+Ridge\n",
        "\n",
        "\n",
        "### 哪個好??都試過才知道"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKXhOIy8JG6n"
      },
      "source": [
        "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\n",
        "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
        "\n",
        "# Lasso\n",
        "cv = LassoCV(cv=10)\n",
        "cv.fit(x_train, y_train_log1p)\n",
        "print(cv.alpha_)\n",
        "model = Lasso(cv.alpha_)\n",
        "model.fit(x_train, y_train_log1p)\n",
        "pre = model.predict(x_predict)\n",
        "result = pd.DataFrame({\n",
        "    \"Id\":test_df[\"Id\"],\n",
        "    \"SalePrice\":np.expm1(pre) # exprenatio - 1\n",
        "})\n",
        "result.to_csv(\"lasso.csv\", encoding=\"utf-8\", index=False)\n",
        "result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21cVwFM3LDXi"
      },
      "source": [
        "# Ridge\n",
        "cv = RidgeCV(cv=10)\n",
        "cv.fit(x_train, y_train_log1p)\n",
        "print(cv.alpha_)\n",
        "model = Ridge(cv.alpha_)\n",
        "model.fit(x_train, y_train_log1p)\n",
        "pre = model.predict(x_predict)\n",
        "result = pd.DataFrame({\n",
        "    \"Id\":test_df[\"Id\"],\n",
        "    \"SalePrice\":np.expm1(pre)\n",
        "})\n",
        "result.to_csv(\"ridge.csv\", encoding=\"utf-8\", index=False)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqQ5rb8cLMcP"
      },
      "source": [
        "# Elastic\n",
        "cv = ElasticNetCV(cv=10)\n",
        "cv.fit(x_train, y_train_log1p)\n",
        "print(cv.alpha_)\n",
        "model = ElasticNet(cv.alpha_)\n",
        "model.fit(x_train, y_train_log1p)\n",
        "pre = model.predict(x_predict)\n",
        "result = pd.DataFrame({\n",
        "    \"Id\":test_df[\"Id\"],\n",
        "    \"SalePrice\":np.expm1(pre)\n",
        "})\n",
        "result.to_csv(\"elastic.csv\", encoding=\"utf-8\", index=False)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoinLrzBt2pQ"
      },
      "source": [
        "為了讓資料能進行分析，必須先讓他們變成常態分佈(個別使用log1p / boxcox1p)\n",
        "\n",
        "取得結果後，要記得再換回原本的y值(expm1 / inv_boxcox1p)\n",
        "1. log1p > expm1\n",
        "2. boxcox1p > inv_boxcox1p"
      ]
    }
  ]
}